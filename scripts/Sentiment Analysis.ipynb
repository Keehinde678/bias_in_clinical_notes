{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654ec517-ac7a-437f-b6c2-05573a71f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\kehin\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kehin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kehin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kehin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kehin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2025.10.5)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "================================================================================\n",
      "MIMIC-III SENTIMENT ANALYSIS\n",
      " Loading data...\n",
      "✓ Loaded 50,000 records\n",
      "✓ Filtered to 42,926 records across 5 ethnicities\n",
      "Initializing sentiment analyzers\n",
      " VADER sentiment analyzer initialized\n",
      " TextBlob sentiment analyzer initialized\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Extracting sentiment features from clinical notes...\n",
      "================================================================================\n",
      "This may take 10-15 minutes for 42,926 notes...\n",
      "\n",
      "Extracting VADER sentiment scores...\n",
      " sentiment extracted\n",
      "\n",
      "Extracting TextBlob sentiment scores\n",
      " sentiment extracted\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Install required packages (run once)\n",
    "# pip install textblob vaderSentiment\n",
    "\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MIMIC-III SENTIMENT ANALYSIS\")\n",
    "# LOAD DATA\n",
    "print(\" Loading data...\")\n",
    "\n",
    "df = pd.read_csv('MIMICIII_Cleaned_Merged.csv')\n",
    "print(f\"✓ Loaded {len(df):,} records\")\n",
    "\n",
    "# Filter to top 5 ethnicities\n",
    "top_5_ethnicities = [\n",
    "    'WHITE',\n",
    "    'BLACK/AFRICAN AMERICAN',\n",
    "    'HISPANIC OR LATINO',\n",
    "    'OTHER',\n",
    "    'ASIAN'\n",
    "]\n",
    "\n",
    "df_filtered = df[df['ETHNICITY'].isin(top_5_ethnicities)].copy()\n",
    "print(f\"✓ Filtered to {len(df_filtered):,} records across 5 ethnicities\")\n",
    "\n",
    "# SENTIMENT ANALYSIS METHODS\n",
    "print(\"Initializing sentiment analyzers\")\n",
    "\n",
    "# Initialize VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "# VADER is designed for social media but works well for clinical text\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(\" VADER sentiment analyzer initialized\")\n",
    "print(\" TextBlob sentiment analyzer initialized\")\n",
    "\n",
    "#  EXTRACT SENTIMENT FEATURES\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Extracting sentiment features from clinical notes...\")\n",
    "print(\"=\"*80)\n",
    "print(\"This may take 10-15 minutes for 42,926 notes...\")\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    \"\"\"Get VADER sentiment scores\"\"\"\n",
    "    if pd.isna(text) or len(str(text).strip()) == 0:\n",
    "        return {'neg': 0, 'neu': 0, 'pos': 0, 'compound': 0}\n",
    "    try:\n",
    "        scores = vader_analyzer.polarity_scores(str(text))\n",
    "        return scores\n",
    "    except:\n",
    "        return {'neg': 0, 'neu': 0, 'pos': 0, 'compound': 0}\n",
    "\n",
    "def get_textblob_sentiment(text):\n",
    "    \"\"\"Get TextBlob sentiment (polarity and subjectivity)\"\"\"\n",
    "    if pd.isna(text) or len(str(text).strip()) == 0:\n",
    "        return {'polarity': 0, 'subjectivity': 0}\n",
    "    try:\n",
    "        blob = TextBlob(str(text))\n",
    "        return {\n",
    "            'polarity': blob.sentiment.polarity,\n",
    "            'subjectivity': blob.sentiment.subjectivity\n",
    "        }\n",
    "    except:\n",
    "        return {'polarity': 0, 'subjectivity': 0}\n",
    "\n",
    "def classify_sentiment(compound_score):\n",
    "    \"\"\"Classify sentiment based on VADER compound score\"\"\"\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Extract VADER sentiment\n",
    "print(\"\\nExtracting VADER sentiment scores...\")\n",
    "vader_results = df_filtered['TEXT'].apply(get_vader_sentiment)\n",
    "\n",
    "df_filtered['vader_negative'] = vader_results.apply(lambda x: x['neg'])\n",
    "df_filtered['vader_neutral'] = vader_results.apply(lambda x: x['neu'])\n",
    "df_filtered['vader_positive'] = vader_results.apply(lambda x: x['pos'])\n",
    "df_filtered['vader_compound'] = vader_results.apply(lambda x: x['compound'])\n",
    "df_filtered['vader_sentiment'] = df_filtered['vader_compound'].apply(classify_sentiment)\n",
    "\n",
    "print(\" sentiment extracted\")\n",
    "\n",
    "# Extract TextBlob sentiment\n",
    "print(\"\\nExtracting TextBlob sentiment scores\")\n",
    "textblob_results = df_filtered['TEXT'].apply(get_textblob_sentiment)\n",
    "\n",
    "df_filtered['textblob_polarity'] = textblob_results.apply(lambda x: x['polarity'])\n",
    "df_filtered['textblob_subjectivity'] = textblob_results.apply(lambda x: x['subjectivity'])\n",
    "\n",
    "print(\" sentiment extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd23d020-fe32-4f35-8fba-59accc9564d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Statistical tests for sentiment differences\n",
      "\n",
      " ANOVA Results for Sentiment Features\n",
      "              Feature  F-statistic  df_between  df_within  p-value  eta_squared Significant\n",
      " VADER Negative Score       59.548           4      42921      0.0     0.005519         Yes\n",
      "  VADER Neutral Score       30.832           4      42921      0.0     0.002865         Yes\n",
      " VADER Positive Score       22.059           4      42921      0.0     0.002052         Yes\n",
      " VADER Compound Score       61.385           4      42921      0.0     0.005688         Yes\n",
      "    TextBlob Polarity        7.757           4      42921      0.0     0.000722         Yes\n",
      "TextBlob Subjectivity       47.622           4      42921      0.0     0.004419         Yes\n"
     ]
    }
   ],
   "source": [
    "# STATISTICAL ANALYSIS (ANOVA)\n",
    "print(\" Statistical tests for sentiment differences\")\n",
    "\n",
    "# Prepare groups\n",
    "groups = {eth: df_filtered[df_filtered['ETHNICITY'] == eth] for eth in top_5_ethnicities}\n",
    "\n",
    "# Features to test\n",
    "sentiment_features = [\n",
    "    ('vader_negative', 'VADER Negative Score'),\n",
    "    ('vader_neutral', 'VADER Neutral Score'),\n",
    "    ('vader_positive', 'VADER Positive Score'),\n",
    "    ('vader_compound', 'VADER Compound Score'),\n",
    "    ('textblob_polarity', 'TextBlob Polarity'),\n",
    "    ('textblob_subjectivity', 'TextBlob Subjectivity')\n",
    "]\n",
    "\n",
    "sentiment_anova_results = []\n",
    "\n",
    "for feature, feature_name in sentiment_features:\n",
    "    # Extract data for each group\n",
    "    group_data = [groups[eth][feature].dropna() for eth in top_5_ethnicities]\n",
    "    \n",
    "    # Run ANOVA\n",
    "    f_stat, p_value = f_oneway(*group_data)\n",
    "    \n",
    "    # Calculate effect size (eta-squared)\n",
    "    all_data = df_filtered[feature].dropna()\n",
    "    grand_mean = all_data.mean()\n",
    "    ss_total = np.sum((all_data - grand_mean) ** 2)\n",
    "    ss_between = sum(len(g) * (g.mean() - grand_mean) ** 2 for g in group_data)\n",
    "    eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
    "    \n",
    "    df_between = len(top_5_ethnicities) - 1\n",
    "    df_within = len(all_data) - len(top_5_ethnicities)\n",
    "    \n",
    "    sentiment_anova_results.append({\n",
    "        'Feature': feature_name,\n",
    "        'F-statistic': f_stat,\n",
    "        'df_between': df_between,\n",
    "        'df_within': df_within,\n",
    "        'p-value': p_value,\n",
    "        'eta_squared': eta_squared,\n",
    "        'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "    })\n",
    "\n",
    "sentiment_anova_df = pd.DataFrame(sentiment_anova_results)\n",
    "sentiment_anova_df['F-statistic'] = sentiment_anova_df['F-statistic'].round(3)\n",
    "sentiment_anova_df['p-value'] = sentiment_anova_df['p-value'].round(4)\n",
    "sentiment_anova_df['eta_squared'] = sentiment_anova_df['eta_squared'].round(6)\n",
    "\n",
    "print(\"\\n ANOVA Results for Sentiment Features\")\n",
    "print(sentiment_anova_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679c0f9-d6c0-4651-8116-ce60466a2a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Post-hoc comparisons for significant features\n",
      " VADER Compound Score\n",
      "                Multiple Comparison of Means - Tukey HSD, FWER=0.05                 \n",
      "====================================================================================\n",
      "        group1                 group2         meandiff p-adj   lower   upper  reject\n",
      "------------------------------------------------------------------------------------\n",
      "                 ASIAN BLACK/AFRICAN AMERICAN  -0.3417    0.0 -0.4146 -0.2687   True\n",
      "                 ASIAN     HISPANIC OR LATINO  -0.2695    0.0 -0.3552 -0.1839   True\n",
      "                 ASIAN                  OTHER  -0.1625    0.0 -0.2505 -0.0744   True\n",
      "                 ASIAN                  WHITE  -0.3304    0.0 -0.3973 -0.2635   True\n",
      "BLACK/AFRICAN AMERICAN     HISPANIC OR LATINO   0.0721 0.0147  0.0094  0.1348   True\n",
      "BLACK/AFRICAN AMERICAN                  OTHER   0.1792    0.0  0.1132  0.2452   True\n",
      "BLACK/AFRICAN AMERICAN                  WHITE   0.0113 0.8823 -0.0216  0.0441  False\n",
      "    HISPANIC OR LATINO                  OTHER   0.1071 0.0023  0.0273  0.1868   True\n",
      "    HISPANIC OR LATINO                  WHITE  -0.0609 0.0235 -0.1164 -0.0053   True\n",
      "                 OTHER                  WHITE  -0.1679    0.0 -0.2272 -0.1087   True\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Post-hoc: TextBlob Polarity\n",
      "--------------------------------------------------------------------------------\n",
      "                Multiple Comparison of Means - Tukey HSD, FWER=0.05                \n",
      "===================================================================================\n",
      "        group1                 group2         meandiff p-adj   lower  upper  reject\n",
      "-----------------------------------------------------------------------------------\n",
      "                 ASIAN BLACK/AFRICAN AMERICAN  -0.0025 0.7067  -0.008 0.0029  False\n",
      "                 ASIAN     HISPANIC OR LATINO   0.0036 0.5484 -0.0028 0.0099  False\n",
      "                 ASIAN                  OTHER   0.0011 0.9907 -0.0055 0.0077  False\n",
      "                 ASIAN                  WHITE   0.0022 0.7358 -0.0027 0.0072  False\n",
      "BLACK/AFRICAN AMERICAN     HISPANIC OR LATINO   0.0061 0.0034  0.0014 0.0108   True\n",
      "BLACK/AFRICAN AMERICAN                  OTHER   0.0037 0.2537 -0.0013 0.0086  False\n",
      "BLACK/AFRICAN AMERICAN                  WHITE   0.0048    0.0  0.0023 0.0072   True\n",
      "    HISPANIC OR LATINO                  OTHER  -0.0025 0.7938 -0.0084 0.0035  False\n",
      "    HISPANIC OR LATINO                  WHITE  -0.0013 0.9089 -0.0055 0.0028  False\n",
      "                 OTHER                  WHITE   0.0011 0.9564 -0.0033 0.0055  False\n",
      "-----------------------------------------------------------------------------------\n",
      " Creating sentiment visualizations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# POST-HOC TESTS\n",
    "print(\" Post-hoc comparisons for significant features\")\n",
    "\n",
    "# Post-hoc for VADER Compound (overall sentiment)\n",
    "if sentiment_anova_df[sentiment_anova_df['Feature'] == 'VADER Compound Score']['Significant'].values[0] == 'Yes':\n",
    "    print(\" VADER Compound Score\")\n",
    "    tukey_compound = pairwise_tukeyhsd(\n",
    "        endog=df_filtered['vader_compound'],\n",
    "        groups=df_filtered['ETHNICITY'],\n",
    "        alpha=0.05\n",
    "    )\n",
    "    print(tukey_compound)\n",
    "\n",
    "# Post-hoc for TextBlob Polarity\n",
    "if sentiment_anova_df[sentiment_anova_df['Feature'] == 'TextBlob Polarity']['Significant'].values[0] == 'Yes':\n",
    "    print(\"\\n\\nPost-hoc: TextBlob Polarity\")\n",
    "    print(\"-\" * 80)\n",
    "    tukey_polarity = pairwise_tukeyhsd(\n",
    "        endog=df_filtered['textblob_polarity'],\n",
    "        groups=df_filtered['ETHNICITY'],\n",
    "        alpha=0.05\n",
    "    )\n",
    "    print(tukey_polarity)\n",
    "\n",
    "# VISUALIZATIONS\n",
    "print(\" Creating sentiment visualizations\")\n",
    "# Mapping dictionary for ethnicities\n",
    "Ethnicity_Label = {\n",
    "    \"WHITE\": \"White\",\n",
    "    \"BLACK/AFRICAN AMERICAN\": \"Black\",\n",
    "    \"ASIAN\": \"Asian\",\n",
    "    \"HISPANIC OR LATINO\": \"Hispanic\",\n",
    "    \"OTHER\": \"Other\"\n",
    "}\n",
    "\n",
    "df_filtered['Ethnicity_Short'] = df_filtered['ETHNICITY'].map(Ethnicity_Label)\n",
    "\n",
    "# Figure 1: VADER Sentiment Components\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 2 — Function to compute VADER sentiment\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "def get_vader_scores(text):\n",
    "    if pd.isna(text):\n",
    "        return pd.Series([0,0,0,0])\n",
    "    scores = analyzer.polarity_scores(str(text))\n",
    "    return pd.Series([\n",
    "        scores['neg'],\n",
    "        scores['pos'],\n",
    "        scores['neu'],\n",
    "        scores['compound']\n",
    "    ])\n",
    "    scores = analyzer.polarity_scores(str(text))\n",
    "    return pd.Series([\n",
    "        scores['neg'],\n",
    "        scores['pos'],\n",
    "        scores['neu'],\n",
    "        scores['compound']\n",
    "    ])\n",
    "\n",
    "df_filtered[['VADER_Negative', 'VADER_Positive', 'VADER_Neutral', 'VADER_Compound']] = \\\n",
    "    df_filtered['TEXT'].apply(get_vader_scores)\n",
    "\n",
    "\n",
    "sentiment_df = df_filtered.groupby('Ethnicity_Short')[[\n",
    "    'VADER_Negative', \n",
    "    'VADER_Positive', \n",
    "    'VADER_Neutral', \n",
    "    'VADER_Compound'\n",
    "]].mean().reset_index()\n",
    "\n",
    "# Negative sentiment\n",
    "sns.barplot(data=sentiment_df, x='Ethnicity', y='VADER_Negative', \n",
    "            palette='Reds_d', ax=axes[0,0])\n",
    "axes[0,0].set_title('VADER Negative Sentiment by Ethnicity', fontsize=12, fontweight='bold')\n",
    "axes[0,0].set_ylabel('Mean Score', fontsize=10)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Neutral sentiment\n",
    "sns.barplot(data=sentiment_df, x='Ethnicity', y='VADER_Neutral',\n",
    "            palette='Greys_d', ax=axes[0,1])\n",
    "axes[0,1].set_title('VADER Neutral Sentiment by Ethnicity', fontsize=12, fontweight='bold')\n",
    "axes[0,1].set_ylabel('Mean Score', fontsize=10)\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Positive sentiment\n",
    "sns.barplot(data=sentiment_df, x='Ethnicity', y='VADER_Positive',\n",
    "            palette='Greens_d', ax=axes[1,0])\n",
    "axes[1,0].set_title('VADER Positive Sentiment by Ethnicity', fontsize=12, fontweight='bold')\n",
    "axes[1,0].set_ylabel('Mean Score', fontsize=10)\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Compound sentiment\n",
    "sns.barplot(data=sentiment_df, x='Ethnicity', y='VADER_Compound',\n",
    "            palette='Blues_d', ax=axes[1,1])\n",
    "axes[1,1].set_title('VADER Compound Sentiment by Ethnicity', fontsize=12, fontweight='bold')\n",
    "axes[1,1].set_ylabel('Mean Score', fontsize=10)\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vader_sentiment_by_ethnicity.png', dpi=300, bbox_inches='tight')\n",
    "print(\"vader_sentiment_by_ethnicity.png\")\n",
    "plt.show()\n",
    "\n",
    "# Figure 2: TextBlob Sentiment\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.barplot(data=sentiment_df, x='Ethnicity', y='TextBlob_Polarity',\n",
    "            palette='RdYlGn', ax=ax1)\n",
    "ax1.set_title('TextBlob Polarity by Ethnicity', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Polarity Score (-1 to +1)', fontsize=12)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "sns.barplot(data=sentiment_df, x='Ethnicity', y='TextBlob_Subjectivity',\n",
    "            palette='Purples_d', ax=ax2)\n",
    "ax2.set_title('TextBlob Subjectivity by Ethnicity', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Subjectivity Score (0 to 1)', fontsize=12)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('textblob_sentiment_by_ethnicity.png', dpi=300, bbox_inches='tight')\n",
    "print(\" textblob_sentiment_by_ethnicity.png\")\n",
    "plt.show()\n",
    "\n",
    "# Figure 3: Sentiment Category Distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sentiment_counts = df_filtered.groupby(['Ethnicity_Short', 'vader_sentiment']).size().unstack(fill_value=0)\n",
    "sentiment_counts_pct = sentiment_counts.div(sentiment_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "sentiment_counts_pct.plot(kind='bar', stacked=True, ax=ax, \n",
    "                         color=['#d62728', '#7f7f7f', '#2ca02c'])\n",
    "ax.set_title('Sentiment Distribution by Ethnicity (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Ethnicity', fontsize=12)\n",
    "ax.set_ylabel('Percentage', fontsize=12)\n",
    "ax.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_distribution_by_ethnicity.png', dpi=300, bbox_inches='tight')\n",
    "print(\" sentiment_distribution_by_ethnicity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1da89-6db8-4e2b-96fd-14b65c4fae6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
